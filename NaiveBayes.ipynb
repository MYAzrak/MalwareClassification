{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4abe128b-ab0f-4112-9ab8-d05d8d9547be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f35a8ec0-3b6f-4e98-b4df-c72ec52d472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary = pd.read_csv(\"PreprocessedUnscaledBinaryClassification.csv\") \n",
    "df_ternary = pd.read_csv(\"PreprocessedUnscaledTernaryClassification.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ba518a5-ccb4-43cd-bb9f-ba584c53d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHyperParam(node_count, avg_train_acc, avg_test_acc, title):\n",
    "    # Convert the list to a numpy array\n",
    "    avg_train_acc = np.array(avg_train_acc)\n",
    "    avg_test_acc = np.array(avg_test_acc)\n",
    "\n",
    "    unique_X = np.unique(node_count)\n",
    "\n",
    "    # Initialize an empty list to store average Y values\n",
    "    average_train = []\n",
    "\n",
    "    # Compute the average Y for each unique X\n",
    "    for x in unique_X:\n",
    "        indices = np.where(node_count == x)[0]\n",
    "        average_train.append(np.mean(avg_train_acc[indices]))\n",
    "\n",
    "    average_test = []\n",
    "    for x in unique_X:\n",
    "        indices = np.where(node_count == x)[0]\n",
    "        average_test.append(np.mean(avg_test_acc[indices]))\n",
    "\n",
    "    plt.plot(unique_X, average_train, marker='o', label='Training Accuracy')\n",
    "    plt.plot(unique_X, average_test, marker='s', label='Testing Accuracy')\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.xlabel('Number of Nodes')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "\n",
    "    # Show plot\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0681dfc-630a-4ab8-a68b-bd8139ed0a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, df, binary=True, distribution=GaussianNB):\n",
    "        if binary:\n",
    "            self.y = df['Label'].to_numpy()\n",
    "            self.X = df.drop(columns=['Label']).to_numpy()\n",
    "        else:\n",
    "            self.y = df['SubType'].to_numpy()\n",
    "            self.X = df.drop(columns=['SubType']).to_numpy()\n",
    "\n",
    "        self.model = distribution()\n",
    "        self.binary = binary\n",
    "\n",
    "    def getAvgScores(self, n=10):\n",
    "        avgTestAcc = 0\n",
    "        avgTestFScore = 0\n",
    "        avgTrainAcc = 0\n",
    "        avgTrainFScore = 0\n",
    "        scoring = 'binary' if self.binary else 'macro'\n",
    "        for i in range(n):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size = 0.2)\n",
    "            self.model.fit(X_train, y_train)\n",
    "            \n",
    "            avgTrainAcc += self.model.score(X_train, y_train)\n",
    "            avgTestAcc += self.model.score(X_test, y_test)\n",
    "            \n",
    "            avgTrainFScore += f1_score(y_train, self.model.predict(X_train), average=scoring)\n",
    "            avgTestFScore += f1_score(y_test, self.model.predict(X_test), average=scoring)\n",
    "\n",
    "        avgTestAcc /= n\n",
    "        avgTrainAcc /= n\n",
    "\n",
    "        avgTestFScore /= n\n",
    "        avgTrainFScore /= n\n",
    "\n",
    "        return {\"Train Accuracy\": avgTrainAcc, \"Test Accuracy\": avgTestAcc, \"Train F Score\": avgTrainFScore, \"Test F Score\": avgTestFScore}\n",
    "        \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "920d71ad-ebda-4e3e-9c55-9ff2b76d6fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ForGaussianNB\n",
      "{'Train Accuracy': 0.9924667715042762, 'Test Accuracy': 0.9919610546269171, 'Train F Score': 0.9924318559943244, 'Test F Score': 0.9919412367075943}\n",
      "\n",
      "\n",
      "ForMultinomialNB\n",
      "{'Train Accuracy': 0.5520346394950563, 'Test Accuracy': 0.5529295192141995, 'Train F Score': 0.17819825713378687, 'Test F Score': 0.1769118631874124}\n",
      "\n",
      "\n",
      "ForComplementNB\n",
      "{'Train Accuracy': 0.5521940501066328, 'Test Accuracy': 0.5523522316043427, 'Train F Score': 0.17836223344020047, 'Test F Score': 0.17648501621068013}\n",
      "\n",
      "\n",
      "ForBernoulliNB\n",
      "{'Train Accuracy': 0.5850218651041554, 'Test Accuracy': 0.5863088057901085, 'Train F Score': 0.5897877560305687, 'Test F Score': 0.5896252618526464}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [GaussianNB, MultinomialNB, ComplementNB, BernoulliNB]:\n",
    "    print(\"For\" + model.__name__)\n",
    "    binModel = NaiveBayes(df=df_binary, binary=True, distribution=model)\n",
    "    print(binModel.getAvgScores(n=10))\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c3df83af-accb-4d94-999c-bb191274c297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ForGaussianNB\n",
      "{'Train Accuracy': 0.39292657524735286, 'Test Accuracy': 0.38871919472405414, 'Train F Score': 0.3042019398886644, 'Test F Score': 0.2990646897445889}\n",
      "\n",
      "\n",
      "ForMultinomialNB\n",
      "{'Train Accuracy': 0.36862523867384134, 'Test Accuracy': 0.36763276640055537, 'Train F Score': 0.24828891171854767, 'Test F Score': 0.2487152196624333}\n",
      "\n",
      "\n",
      "ForComplementNB\n",
      "{'Train Accuracy': 0.3673233813574032, 'Test Accuracy': 0.3689864630336689, 'Train F Score': 0.2460674080816294, 'Test F Score': 0.2477780911881045}\n",
      "\n",
      "\n",
      "ForBernoulliNB\n",
      "{'Train Accuracy': 0.34975698663426497, 'Test Accuracy': 0.34989586948976054, 'Train F Score': 0.2935129148727814, 'Test F Score': 0.2940926067106803}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [GaussianNB, MultinomialNB, ComplementNB, BernoulliNB]:\n",
    "    print(\"For\" + model.__name__)\n",
    "    binModel = NaiveBayes(df=df_ternary, binary=False, distribution=model)\n",
    "    print(binModel.getAvgScores(n=10))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e33f746-9783-4bc6-9012-50026f233afe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
